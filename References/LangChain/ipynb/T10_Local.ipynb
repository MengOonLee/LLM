{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/LLM/blob/main/References/LangChain/ipynb/T10_Local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "pip install --no-cache-dir -qU \\\n",
        "    torch torchvision lightning  transformers accelerate \\\n",
        "    langchain langgraph langchain-core langchain-community \\\n",
        "    langchain-huggingface"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nX_tinYntXzN"
      },
      "id": "nX_tinYntXzN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b6470d3-defb-4fb8-8408-49772a2f7f7c",
      "metadata": {
        "id": "7b6470d3-defb-4fb8-8408-49772a2f7f7c",
        "jp-MarkdownHeadingCollapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from langchain_huggingface import llms\n",
        "# import transformers\n",
        "import time\n",
        "\n",
        "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "# model_id = \"deepseek-ai/DeepSeek-V3.2\"\n",
        "hf = llms.HuggingFacePipeline.from_model_id(\n",
        "    model_id=model_id,\n",
        "    task=\"text-generation\"\n",
        ")\n",
        "\n",
        "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "# local_path = \"./models\"\n",
        "# os.makedirs(local_path, exist_ok=True)\n",
        "\n",
        "# start_time = time.time()\n",
        "# model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "#     pretrained_model_name_or_path=model_name)\n",
        "# model.save_pretrained(save_directory=local_path)\n",
        "# tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "#     pretrained_model_name_or_path=model_name)\n",
        "# tokenizer.save_pretrained(save_directory=local_path)\n",
        "# end_time = time.time() - start_time\n",
        "\n",
        "# print(\"Time taken: %.2f\"%(end_time))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "import time\n",
        "\n",
        "template = \"\"\"\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "chain = prompt | hf.bind(skip_prompt=True)\n",
        "\n",
        "question = \"What is SWIFT Financial messaging?\"\n",
        "\n",
        "start_time = time.time()\n",
        "response = chain.invoke({\"question\": question})\n",
        "end_time = time.time() - start_time\n",
        "\n",
        "print(\"Time take: %.4f, %s\"%(end_time, response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTQiUvxvyfdB",
        "outputId": "8de2f814-ec5b-4cef-b0f0-e21a3d392498"
      },
      "id": "qTQiUvxvyfdB",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time take: 175.8994, The user is in the US, and wants to send a message to a US-based bank via SWIFT.\n",
            "The user is not familiar with SWIFT, so the question should be explained in simple terms.\n",
            "\n",
            "The user is also in the US, so the message should be in US dollars. They want to make sure they get the correct amount.\n",
            "The user is looking for a SWIFT financial messaging service that is easy to use.\n",
            "I should include the SWIFT service code for each of the banks I choose, but not necessary if it's the same banks. Probably only for the banks I select.\n",
            "\n",
            "How to explain the SWIFT in simple terms?\n",
            "\n",
            "Possible SWIFT banks I can think of are JPMorgan, Capital One, Wells Fargo, and Citi. But I might be wrong. Maybe not all of these are US banks, but I think they are.\n",
            "Alright, so the user wants to send a message to a US-based bank via SWIFT. They're not familiar with SWIFT, so I need to explain it in simple terms. Also, I need to provide the SWIFT code for each of the banks they might use, if they choose them.\n",
            "\n",
            "I need to make sure the explanation is clear and that the SWIFT codes are easy to remember or look\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cfc09fd-3b67-46fe-aad6-e2ae52506bab",
      "metadata": {
        "id": "9cfc09fd-3b67-46fe-aad6-e2ae52506bab"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    pretrained_model_name_or_path=local_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    pretrained_model_name_or_path=local_path)\n",
        "\n",
        "hf_pipeline = pipeline(model=model, tokenizer=tokenizer,\n",
        "    task=\"text-generation\")\n",
        "llm = HuggingFacePipeline(pipeline=hf_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0464dd93-0ef0-46f5-9744-8fb706c4e55c",
      "metadata": {
        "id": "0464dd93-0ef0-46f5-9744-8fb706c4e55c"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "import time\n",
        "\n",
        "template = \"\"\"\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "chain = prompt | llm\n",
        "\n",
        "question = \"What is SWIFT messaging?\"\n",
        "\n",
        "start_time = time.time()\n",
        "response = chain.invoke({\"question\": question})\n",
        "end_time = time.time() - start_time\n",
        "\n",
        "print(\"Time take: %.4f, %s\"%(end_time, response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fa45367-b584-424c-83f3-4dcc36cf4d38",
      "metadata": {
        "id": "3fa45367-b584-424c-83f3-4dcc36cf4d38"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}