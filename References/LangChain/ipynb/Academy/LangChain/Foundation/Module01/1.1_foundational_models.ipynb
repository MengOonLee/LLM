{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/LLM/blob/main/References/LangChain/ipynb/Academy/LangChain/Foundation/Module01/1.1_foundational_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "apt install -y zstd\n",
        "apt install -y pciutils lshw\n",
        "curl -fsSL https://ollama.com/install.sh | sh\n",
        "pip install --no-cache-dir -qU \\\n",
        "    langchain langgraph langchain-core langchain-community \\\n",
        "    langchain-ollama ollama"
      ],
      "metadata": {
        "id": "v1sQ_ZG5PPya"
      },
      "id": "v1sQ_ZG5PPya",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve &"
      ],
      "metadata": {
        "id": "jOT1q9uUTK3O"
      },
      "id": "jOT1q9uUTK3O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull gpt-oss:20b"
      ],
      "metadata": {
        "id": "3N0gaWTaTQjP"
      },
      "id": "3N0gaWTaTQjP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "106cf38c",
      "metadata": {
        "id": "106cf38c"
      },
      "outputs": [],
      "source": [
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "810e9c4a",
      "metadata": {
        "id": "810e9c4a"
      },
      "source": [
        "## Initialising and invoking a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26c3ed29",
      "metadata": {
        "id": "26c3ed29"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(model=\"gpt-5-nano\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf3ad14",
      "metadata": {
        "id": "acf3ad14"
      },
      "outputs": [],
      "source": [
        "response = model.invoke(\"What's the capital of the Moon?\")\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee8e957",
      "metadata": {
        "id": "4ee8e957"
      },
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "673a54e0",
      "metadata": {
        "id": "673a54e0"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(response.response_metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf169b71",
      "metadata": {
        "id": "bf169b71"
      },
      "source": [
        "## Customising your Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86f50c22",
      "metadata": {
        "id": "86f50c22"
      },
      "outputs": [],
      "source": [
        "model = init_chat_model(\n",
        "    model=\"gpt-5-nano\",\n",
        "    # Kwargs passed to the model:\n",
        "    temperature=1.0\n",
        ")\n",
        "\n",
        "response = model.invoke(\"What's the capital of the Moon?\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c14f450",
      "metadata": {
        "id": "8c14f450"
      },
      "source": [
        "## Model Providers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dcf1d9f",
      "metadata": {
        "id": "6dcf1d9f"
      },
      "source": [
        "https://docs.langchain.com/oss/python/integrations/chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db029be",
      "metadata": {
        "id": "5db029be"
      },
      "outputs": [],
      "source": [
        "model = init_chat_model(model=\"claude-sonnet-4-5\")\n",
        "\n",
        "response = model.invoke(\"What's the capital of the Moon?\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ece1cfc2",
      "metadata": {
        "id": "ece1cfc2"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\")\n",
        "\n",
        "response = model.invoke(\"What's the capital of the Moon?\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc723f48",
      "metadata": {
        "id": "fc723f48"
      },
      "source": [
        "## Initialising and invoking an agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fbc17be",
      "metadata": {
        "id": "3fbc17be"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "\n",
        "agent = create_agent(model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "698ef4c5",
      "metadata": {
        "id": "698ef4c5"
      },
      "outputs": [],
      "source": [
        "agent = create_agent(model=\"claude-sonnet-4-5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c56a05e9",
      "metadata": {
        "id": "c56a05e9"
      },
      "outputs": [],
      "source": [
        "agent = create_agent(\"gpt-5-nano\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5251725",
      "metadata": {
        "id": "c5251725"
      },
      "outputs": [],
      "source": [
        "from langchain.messages import HumanMessage\n",
        "\n",
        "response = agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What's the capital of the Moon?\")]}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac95763",
      "metadata": {
        "id": "2ac95763"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a8e6ec",
      "metadata": {
        "id": "00a8e6ec"
      },
      "outputs": [],
      "source": [
        "print(response['messages'][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca5da573",
      "metadata": {
        "id": "ca5da573"
      },
      "outputs": [],
      "source": [
        "from langchain.messages import AIMessage\n",
        "\n",
        "response = agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What's the capital of the Moon?\"),\n",
        "    AIMessage(content=\"The capital of the Moon is Luna City.\"),\n",
        "    HumanMessage(content=\"Interesting, tell me more about Luna City\")]}\n",
        ")\n",
        "\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dcf635e",
      "metadata": {
        "id": "0dcf635e"
      },
      "source": [
        "## Streaming Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7075c1c1",
      "metadata": {
        "id": "7075c1c1"
      },
      "outputs": [],
      "source": [
        "for token, metadata in agent.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Tell me all about Luna City, the capital of the Moon\")]},\n",
        "    stream_mode=\"messages\"\n",
        "):\n",
        "\n",
        "    # token is a message chunk with token content\n",
        "    # metadata contains which node produced the token\n",
        "\n",
        "    if token.content:  # Check if there's actual content\n",
        "        print(token.content, end=\"\", flush=True)  # Print token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23ef691a",
      "metadata": {
        "id": "23ef691a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}