{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8613af03-69d3-4abb-8aaf-56417297a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import dotenv\n",
    "import langchain_huggingface\n",
    "\n",
    "_ = dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "\n",
    "repo_id = \"deepseek-ai/DeepSeek-V3.2\"\n",
    "llm_model = langchain_huggingface.HuggingFaceEndpoint(\n",
    "    huggingfacehub_api_token=os.environ['HF_TOKEN'],\n",
    "    repo_id=repo_id, provider='auto', temperature=0.5\n",
    ")\n",
    "llm = langchain_huggingface.ChatHuggingFace(\n",
    "    llm=llm_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b128c-59c0-4313-a6b7-51ece433e44e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4503bba6-cba5-467e-ae59-2fde1ae3300b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 7.37, Response: Ahoy there, me hearty customer! 'Tis a gentle reminder from yer friendly crew that the warranty be not coverin' the costs o' cleanin' yer galley. \n",
      "\n",
      "Alas, the mishap be due to a wee oversightâ€”ye forgot to secure the lid afore settin' yer blender to the high seas. 'Tis a bit o' bad fortune, but the responsibility falls upon yer own shoulders, as the terms o' the warranty be clear on such matters. \n",
      "\n",
      "We wish ye smooth sailin' ahead, and may yer future blendin' be ever smooth and tidy! Fare thee well, matey!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core import prompts\n",
    "import time\n",
    "\n",
    "service_template = \"\"\"\n",
    "Translate the text that is delimited by triple backticks into a \n",
    "style that is {style}. text: ```{text}```\n",
    "\"\"\"\n",
    "prompt_template = prompts.ChatPromptTemplate.from_template(\n",
    "    template=service_template\n",
    ")\n",
    "\n",
    "service_style_pirate = \"\"\"\n",
    "a polite tone that speaks in English Pirate\n",
    "\"\"\"\n",
    "\n",
    "service_reply = \"\"\"\n",
    "Hey there customer, the warranty does not cover cleaning \n",
    "expenses for your kitchen because it's your fault that you \n",
    "misused your blender by forgetting to put the lid on before \n",
    "starting the blender. Tough luck! See ya!\n",
    "\"\"\"\n",
    "\n",
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "service_response = llm.invoke(input=service_messages)\n",
    "end_time = time.time() - start_time\n",
    "print(\"Duration: %.2f, Response: %s\"%(end_time, service_response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfe05b9-d40b-4a3f-bda7-7a22db3f8a11",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16aca0b8-44ac-4a53-bdf0-75ec0d299964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 3.05, Response: ```json\n",
      "{\n",
      "    \"gift\": true,\n",
      "    \"delivery_days\": 2,\n",
      "    \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core import prompts\n",
    "import time\n",
    "\n",
    "review_template = \"\"\"\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else?\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price, \n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = prompts.ChatPromptTemplate.from_template(\n",
    "    template=review_template\n",
    ")\n",
    "\n",
    "customer_review = \"\"\"\n",
    "This leaf blower is pretty amazing.  It has four settings: \n",
    "candle blower, gentle breeze, windy city, and tornado. It \n",
    "arrived in two days, just in time for my wife's anniversary \n",
    "present. I think my wife liked it so much she was speechless. So \n",
    "far I've been the only one using it, and I've been using it \n",
    "every other morning to clear the leaves on our lawn. It's \n",
    "slightly more expensive than the other leaf blowers out there, \n",
    "but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_messages = prompt_template.format_messages(\n",
    "    text=customer_review\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "review_response = llm.invoke(input=review_messages)\n",
    "end_time = time.time() - start_time\n",
    "print(\"Duration: %.2f, Response: %s\"%(end_time, review_response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de20af-b1e0-4e4d-a783-18bf506ada13",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d85e899e-a80a-4d24-ac22-ffe774123372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pydantic\n",
    "from langchain import tools, agents\n",
    "\n",
    "@tools.tool\n",
    "def get_today_date(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns todays date, use this for any questions related to \n",
    "    knowing todays date. The input should always be an empty \n",
    "    string, and this function will always return todays date - \n",
    "    any date mathmatics should occur outside this function.\n",
    "    \"\"\"\n",
    "    return \"Today is %s\"%(str(datetime.date.today()))\n",
    "\n",
    "class DateInfo(pydantic.BaseModel):\n",
    "    date: str\n",
    "\n",
    "agent = agents.create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_today_date],\n",
    "    # response_format=agents.structured_output.ToolStrategy(DateInfo)\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the date today?\"\n",
    "    }]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3e9c33d-b8ad-4884-9f33-a9b2e2d45f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is **January 4, 2026**.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['messages'][-1].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
