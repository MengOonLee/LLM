{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/LLM/blob/main/References/LangChain/ipynb/T01_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "pip install --no-cache-dir -qU \\\n",
        "    python-dotenv scrapy unstructured \\\n",
        "    langchain langgraph langchain-core \\\n",
        "    langchain-community langchain-huggingface \\\n",
        "    openai langchain-openai"
      ],
      "metadata": {
        "id": "z0JWzk4rZ37f"
      },
      "id": "z0JWzk4rZ37f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3f38d025-4c75-4815-abb5-1cd9fbe0cc53",
      "metadata": {
        "id": "3f38d025-4c75-4815-abb5-1cd9fbe0cc53"
      },
      "source": [
        "## LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8613af03-69d3-4abb-8aaf-56417297a53f",
      "metadata": {
        "id": "8613af03-69d3-4abb-8aaf-56417297a53f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import dotenv\n",
        "import langchain_huggingface\n",
        "\n",
        "_ = dotenv.load_dotenv(dotenv_path=\".env\", override=True)\n",
        "\n",
        "# repo_id = \"deepseek-ai/DeepSeek-V3.2\"\n",
        "repo_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\"\n",
        "llm_endpoint = langchain_huggingface.HuggingFaceEndpoint(\n",
        "    huggingfacehub_api_token=os.environ['HF_TOKEN'],\n",
        "    repo_id=repo_id, task=\"text-generation\",\n",
        "    provider='auto', temperature=0.1\n",
        ")\n",
        "llm = langchain_huggingface.ChatHuggingFace(llm=llm_endpoint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import dotenv\n",
        "import openai\n",
        "\n",
        "_ = dotenv.load_dotenv(dotenv_path=\".env\", override=True)\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url=\"https://router.huggingface.co/v1\",\n",
        "    api_key=os.environ['HF_TOKEN']\n",
        ")\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is the capital of France?\"\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "ZquieL4kkDf4",
        "outputId": "24baec5c-717c-4870-8092-e335c28ea577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZquieL4kkDf4",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<openai.OpenAI at 0x7e18123c2030>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf2b128c-59c0-4313-a6b7-51ece433e44e",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "cf2b128c-59c0-4313-a6b7-51ece433e44e"
      },
      "source": [
        "## Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4503bba6-cba5-467e-ae59-2fde1ae3300b",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4503bba6-cba5-467e-ae59-2fde1ae3300b",
        "outputId": "303bdea1-de1e-4dc9-e0c8-45e3db8605b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration: 14.86, Response: <think>\n",
            "Alright, so I've got this query where the user wants me to translate some text into a polite pirate-style English. Let me break this down.\n",
            "\n",
            "First, the original text is pretty straightforward but a bit harsh. It's telling a customer that their warranty doesn't cover cleaning expenses because they misused their blender by not putting the lid on. The tone is kind of blunt, ending with \"Tough luck! See ya!\" which isn't very friendly.\n",
            "\n",
            "The user wants this translated into a polite pirate tone. So, I need to maintain the message but make it sound more courteous and pirate-like. Pirates have a distinct way of speaking, using words like \"Arrr,\" \"matey,\" \"aye,\" and phrases that evoke a sense of camaraderie and old-timey speech.\n",
            "\n",
            "I should start by addressing the customer in a friendly pirate manner. Instead of \"Hey there customer,\" maybe \"Ahoy, valued customer!\" sounds better. It's more welcoming and sets a positive tone.\n",
            "\n",
            "Next, the part about the warranty not covering cleaning expenses. I need to phrase this in a way that's clear but gentle. Maybe something like, \"unfortunately, the warranty doesn't cover the cleanin' o' yer kitchen.\" Using \"o'\" instead of \"of\" gives it that pirate flair.\n",
            "\n",
            "Then, explaining why the warranty doesn't apply. The original says it's the customer's fault for misusing the blender by forgetting the lid. I can rephrase that to \"ye be responsible for the mess\" but in a way that's not blaming. Maybe \"it seems ye be responsible for the mess, since ye forgot to slap the lid on before startin' up yer trusty blender.\" Adding \"trustee\" or \"trusty\" makes it sound more pirate-like.\n",
            "\n",
            "Finally, the closing should maintain politeness. Instead of \"Tough luck! See ya!\" maybe \"Aye, that be the way o' things. Take care, and may yer future blends be lid-tight and trouble-free!\" This keeps it friendly and hopeful, encouraging the customer to have better experiences in the future.\n",
            "\n",
            "I also need to ensure that the pirate terms are consistent and not overdone. It should be enough to give it that pirate feel without making it hard to understand. Words like \"Arrr\" at the end can add a nice touch without being overwhelming.\n",
            "\n",
            "Putting it all together, I think the response I came up with hits the right notes. It's polite, uses pirate lingo appropriately, and maintains a helpful\n"
          ]
        }
      ],
      "source": [
        "from langchain_core import prompts\n",
        "import time\n",
        "\n",
        "service_template = \"\"\"\n",
        "Translate the text that is delimited by triple backticks into a\n",
        "style that is {style}. text: ```{text}```\n",
        "\"\"\"\n",
        "prompt_template = prompts.ChatPromptTemplate.from_template(\n",
        "    template=service_template\n",
        ")\n",
        "\n",
        "service_style_pirate = \"\"\"\n",
        "a polite tone that speaks in English Pirate\n",
        "\"\"\"\n",
        "\n",
        "service_reply = \"\"\"\n",
        "Hey there customer, the warranty does not cover cleaning\n",
        "expenses for your kitchen because it's your fault that you\n",
        "misused your blender by forgetting to put the lid on before\n",
        "starting the blender. Tough luck! See ya!\n",
        "\"\"\"\n",
        "\n",
        "service_messages = prompt_template.format_messages(\n",
        "    style=service_style_pirate,\n",
        "    text=service_reply\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "service_response = llm.invoke(input=service_messages)\n",
        "end_time = time.time() - start_time\n",
        "print(\"Duration: %.2f, Response: %s\"%(end_time, service_response.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dfe05b9-d40b-4a3f-bda7-7a22db3f8a11",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "6dfe05b9-d40b-4a3f-bda7-7a22db3f8a11"
      },
      "source": [
        "## Output Parsers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "16aca0b8-44ac-4a53-bdf0-75ec0d299964",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16aca0b8-44ac-4a53-bdf0-75ec0d299964",
        "outputId": "36348988-18eb-4576-84a5-324802a39b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration: 2.84, Response: ```json\n",
            "{\n",
            "  \"gift\": true,\n",
            "  \"delivery_days\": 2,\n",
            "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "from langchain_core import prompts\n",
        "import time\n",
        "\n",
        "review_template = \"\"\"\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else?\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "gift\n",
        "delivery_days\n",
        "price_value\n",
        "\n",
        "text: {text}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = prompts.ChatPromptTemplate.from_template(\n",
        "    template=review_template\n",
        ")\n",
        "\n",
        "customer_review = \"\"\"\n",
        "This leaf blower is pretty amazing.  It has four settings:\n",
        "candle blower, gentle breeze, windy city, and tornado. It\n",
        "arrived in two days, just in time for my wife's anniversary\n",
        "present. I think my wife liked it so much she was speechless. So\n",
        "far I've been the only one using it, and I've been using it\n",
        "every other morning to clear the leaves on our lawn. It's\n",
        "slightly more expensive than the other leaf blowers out there,\n",
        "but I think it's worth it for the extra features.\n",
        "\"\"\"\n",
        "\n",
        "review_messages = prompt_template.format_messages(\n",
        "    text=customer_review\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "review_response = llm.invoke(input=review_messages)\n",
        "end_time = time.time() - start_time\n",
        "print(\"Duration: %.2f, Response: %s\"%(end_time, review_response.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06de20af-b1e0-4e4d-a783-18bf506ada13",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "06de20af-b1e0-4e4d-a783-18bf506ada13"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d85e899e-a80a-4d24-ac22-ffe774123372",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "d85e899e-a80a-4d24-ac22-ffe774123372",
        "outputId": "9db7dac7-f95c-4ec1-885a-5f782edbc595"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "(Request ID: Root=1-6965850e-1a5723e8081425eb02d50cab;6bb184e7-6ca7-4e36-8405-8669cb8b8819)\n\nBad request:",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://router.huggingface.co/novita/v3/openai/chat/completions",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1054700456.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m response = agent.invoke({\n\u001b[0m\u001b[1;32m     20\u001b[0m     \"messages\": [{\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3069\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   3072\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2644\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2647\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    168\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/factory.py\u001b[0m in \u001b[0;36mmodel_node\u001b[0;34m(state, runtime)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwrap_model_call_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;31m# No handlers - execute directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute_model_sync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[0;31m# Call composed handler with base handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/factory.py\u001b[0m in \u001b[0;36m_execute_model_sync\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5555\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5556\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5557\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5558\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5559\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m             cast(\n\u001b[1;32m    401\u001b[0m                 \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                 self.generate_prompt(\n\u001b[0m\u001b[1;32m    403\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1120\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                 results.append(\n\u001b[0;32m--> 931\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    932\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1234\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_huggingface/chat_models/huggingface.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             }\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mllm_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_chat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mchat_completion\u001b[0;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         )\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36m_inner_post\u001b[0;34m(self, request_parameters, stream)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0;34mf\"\\n\\nBad request for {endpoint_name} endpoint:\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mendpoint_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\\n\\nBad request:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             )\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBadRequestError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m403\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: (Request ID: Root=1-6965850e-1a5723e8081425eb02d50cab;6bb184e7-6ca7-4e36-8405-8669cb8b8819)\n\nBad request:"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "from langchain import tools, agents\n",
        "\n",
        "@tools.tool\n",
        "def get_today_date(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Returns todays date, use this for any questions related to\n",
        "    knowing todays date. The input should always be an empty\n",
        "    string, and this function will always return todays date -\n",
        "    any date mathmatics should occur outside this function.\n",
        "    \"\"\"\n",
        "    return \"Today is %s\"%(str(datetime.date.today()))\n",
        "\n",
        "agent = agents.create_agent(\n",
        "    model=llm,\n",
        "    tools=[get_today_date]\n",
        ")\n",
        "\n",
        "response = agent.invoke({\n",
        "    \"messages\": [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What is the date today?\"\n",
        "    }]\n",
        "})\n",
        "print(response['messages'][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a887e32-75d9-4f5e-a2a7-d968d1d38671",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "8a887e32-75d9-4f5e-a2a7-d968d1d38671"
      },
      "source": [
        "## Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc55a322-ca4b-40f7-aef9-ac1376e0e445",
      "metadata": {
        "id": "dc55a322-ca4b-40f7-aef9-ac1376e0e445"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install --no-cache-dir -qU wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e5d226d-69ae-4194-ab83-f8845c4361c7",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "1e5d226d-69ae-4194-ab83-f8845c4361c7",
        "outputId": "e30477aa-0851-40e6-f905-c2322715fd2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Wikipedia summary: The Society for Worldwide Interbank Financial Telecommunication (SWIFT), legally S.W.I.F.T. SC, is a cooperative established in 1973 in Belgium (French: Société Coopérative) and owned by the banks and other member firms that use its service. SWIFT provides the main messaging network through which international payments are initiated. It also sells software and services to financial institutions, mostly for use on its proprietary \"SWIFTNet\", and assigns ISO 9362 Business Identifier Codes (BICs), popularly known as \"SWIFT codes\".\\nAs of 2018, around half of all high-value cross-border payments worldwide used the SWIFT network, and in 2015, SWIFT linked more than 11,000 financial institutions in over 200 countries and territories, who were exchanging an average of over 32 million messages per day (compared to an average of 2.4 million daily messages in 1995).\\nSWIFT is headquartered in La Hulpe near Brussels. It hosts an annual conference, called Sibos, specifically aimed at the financial services industry.\\n\\n\\n== History ==\\nBefore SWIFT\\'s establishment, international financial transactions were communicated over Telex, a public system involving manual writing and reading of messages. SWIFT was set up out of fear of what might happen if a single private and fully American entity controlled global financial flows – which before was First National City Bank (FNCB) of New York – later Citibank.'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import tools\n",
        "import wikipedia\n",
        "import typing\n",
        "\n",
        "@tools.tool\n",
        "def wikipedia_tool(\n",
        "    query: typing.Annotated[str, \"\"\"\n",
        "        The Wikipedia search to execute to find key summary information.\n",
        "    \"\"\"]\n",
        "):\n",
        "    \"\"\"\n",
        "    Use this to search wikipedia for factual information.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        results = wikipedia.search(query)\n",
        "        if not results:\n",
        "            return \"No results.\"\n",
        "        title = results[0]\n",
        "        summary = wikipedia.summary(title, sentences=8, auto_suggest=False, redirect=True)\n",
        "    except BaseException as e:\n",
        "        return f\"Error: {repl(e)}\"\n",
        "    return f\"Wikipedia summary: {summary}\"\n",
        "\n",
        "company_name = \"SWIFT Financial Messaging\"\n",
        "wikipedia_tool.invoke(input=f\"{company_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65813715-b6e9-4274-a2b2-691fbedc4617",
      "metadata": {
        "id": "65813715-b6e9-4274-a2b2-691fbedc4617"
      },
      "source": [
        "## Langgraph Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fe90318-ac11-482b-afbd-fe0e47a9b288",
      "metadata": {
        "id": "1fe90318-ac11-482b-afbd-fe0e47a9b288",
        "outputId": "de92b4be-60b4-47a7-981f-0d533969be03"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7fd23773e070>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing_extensions import TypedDict\n",
        "import typing\n",
        "from langgraph import graph\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    messages: typing.Annotated[list, graph.message.add_messages]\n",
        "\n",
        "workflow = graph.StateGraph(state_schema=GraphState)\n",
        "\n",
        "def llm_node(state: GraphState):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "workflow.add_node(node=\"llm\", action=llm_node)\n",
        "\n",
        "workflow.add_edge(start_key=graph.START, end_key=\"llm\")\n",
        "workflow.add_edge(start_key=\"llm\", end_key=graph.END)\n",
        "workflow = workflow.compile()\n",
        "workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19a18321-9218-43aa-944a-d0b6b9a282f7",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "id": "19a18321-9218-43aa-944a-d0b6b9a282f7",
        "outputId": "f2a14c9a-d474-45c2-d981-d898924349e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'llm': {'messages': [AIMessage(content=\"**SWIFT ISO 20022** is a global messaging standard for financial communications that enhances and modernizes how financial institutions exchange data. Here’s a comprehensive overview:\\n\\n---\\n\\n### **1. What is ISO 20022?**\\n- **ISO 20022** is an international standard for financial messaging, designed to create a common language and structure for payments, securities, trade finance, and other financial transactions.\\n- It enables **richer, structured data** to be attached to payment messages, improving automation, compliance, and transparency.\\n\\n---\\n\\n### **2. SWIFT's Role**\\n- **SWIFT (Society for Worldwide Interbank Financial Telecommunication)** is the global network that facilitates financial messaging between banks and institutions.\\n- Historically, SWIFT used its own message formats (like MT messages). However, SWIFT is now migrating to **ISO 20022** for cross-border payments and reporting, aligning with broader industry adoption.\\n\\n---\\n\\n### **3. Key Benefits of ISO 20022**\\n- **Enhanced Data Quality**: Supports longer and more structured fields, enabling detailed remittance information, KYC (Know Your Customer) data, and regulatory details.\\n- **Interoperability**: Allows seamless communication between different payment systems globally (e.g., between SWIFT, SEPA, Fedwire, and others).\\n- **Efficiency**: Reduces manual intervention, errors, and delays through automation and richer data.\\n- **Compliance**: Facilitates adherence to regulations like AML (Anti-Money Laundering) and sanctions screening by carrying structured data.\\n- **Innovation**: Enables new services, like real-time tracking and enriched analytics.\\n\\n---\\n\\n### **4. Main Message Categories**\\nISO 20022 covers a wide range of financial activities:\\n- **Payments**: Customer credit transfers, interbank payments (e.g., `pacs.008` for payment initiation).\\n- **Cash Management**: Account statements and liquidity reporting.\\n- **Securities**: Trade settlement, corporate actions, and reconciliation.\\n- **Trade Finance**: Letters of credit and guarantees.\\n- **Cards**: Card transactions and clearing.\\n\\n---\\n\\n### **5. Migration Timeline**\\n- **SWIFT’s Migration**: SWIFT began migrating its cross-border payments (MT messages) to ISO 20022 in **March 2023**, with a coexistence period until **November 2025**. After that, ISO 20022 will become mandatory for SWIFT users.\\n- **Global Adoption**: Many domestic payment systems (e.g., SEPA in Europe, CHIPS in the US) already use or are adopting ISO 20022.\\n\\n---\\n\\n### **6. Impact on Financial Institutions**\\n- **Technical Upgrades**: Institutions need to update their systems to generate, process, and validate ISO 20022 messages.\\n- **Training**: Staff must learn new message structures and workflows.\\n- **Data Management**: Enhanced data handling capabilities are required to leverage structured information.\\n- **Costs and Investments**: Migration involves significant investment but leads to long-term efficiencies.\\n\\n---\\n\\n### **7. Challenges**\\n- **Complexity**: The standard is detailed and requires careful implementation.\\n- **Transition Risks**: During coexistence, institutions must support both old (MT) and new (ISO 20022) formats.\\n- **Global Coordination**: Harmonizing adoption across countries and systems is challenging.\\n\\n---\\n\\n### **8. Future Outlook**\\n- ISO 20022 is set to become the **universal language** for financial messaging.\\n- It will enable innovation in areas like **real-time payments**, **blockchain integration**, and **AI-driven analytics**.\\n- SWIFT’s adoption accelerates global interoperability, paving the way for a more connected financial ecosystem.\\n\\n---\\n\\n### **Summary**\\nSWIFT ISO 20022 modernizes financial messaging by replacing older formats with a structured, data-rich standard. It enhances efficiency, transparency, and compliance, but requires significant effort from institutions to adopt. The migration is a critical step toward a globally unified payments landscape.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 795, 'prompt_tokens': 18, 'total_tokens': 813}, 'model_name': 'deepseek-ai/DeepSeek-V3.2', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run--44f5e924-ba76-45cc-a28a-ab3132a85908-0', usage_metadata={'input_tokens': 18, 'output_tokens': 795, 'total_tokens': 813})]}}\n"
          ]
        }
      ],
      "source": [
        "for chunk in workflow.stream(\n",
        "    {\"messages\": [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Tell me about SWIFT ISO20022\"\n",
        "    }]}\n",
        "):\n",
        "    print(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6377bb6c-3abe-4964-92fc-12dbf79b7ed5",
      "metadata": {
        "id": "6377bb6c-3abe-4964-92fc-12dbf79b7ed5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "default:Python",
      "language": "python",
      "name": "conda-env-default-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}