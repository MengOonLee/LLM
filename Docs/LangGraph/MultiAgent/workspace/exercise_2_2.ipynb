{"cells":[{"source":"![](images/graph_with_conditional_edges.png)\n\n### ü™ö Making tools optional\n\nIn the last exercise, you saw how the linear workflow directed all LLM outputs into the tool node, irrespective of whether a tool call was required. Let's change this so our system can handle user inputs that don't require tool calls.","metadata":{},"id":"d7b265c2-73df-4a46-add0-67cad208b100","cell_type":"markdown"},{"source":"**Re-run the two cells below to create the environment and define the tools.**","metadata":{},"id":"4825ac52-6b23-4ef2-a24b-8610121419ca","cell_type":"markdown"},{"source":"!pip install --quiet wikipedia==1.4.0 langchain-core==0.3.59 langgraph==0.5.3 langchain-openai==0.3.16 langchain-experimental==0.3.4","metadata":{"executionCancelledAt":null,"executionTime":3132,"lastExecutedAt":1748622603694,"lastExecutedByKernel":"efe21570-8ade-4aab-97ce-0b21ab6784fd","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install --quiet wikipedia==1.4.0 langchain-core==0.3.59 langgraph==0.4.3 langchain-openai==0.3.16 langchain-experimental==0.3.4 langgraph-supervisor==0.0.21","outputsMetadata":{"0":{"height":80,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"2ce4430b-9e12-42d0-b4d5-909067dd3e40","cell_type":"code","execution_count":1,"outputs":[]},{"source":"from typing import Annotated\nimport wikipedia\nfrom langchain_core.tools import tool\nimport pandas as pd\nimport os\n\n@tool\ndef wikipedia_tool(\n    query: Annotated[str, \"The Wikipedia search to execute to find key summary information.\"],\n):\n    \"\"\"Use this to search Wikipedia for factual information.\"\"\"\n    try:\n        # Step 1: Search using query\n        results = wikipedia.search(query)\n        \n        if not results:\n            return \"No results found on Wikipedia.\"\n        \n        # Step 2: Retrieve page title\n        title = results[0]\n\n        # Step 3: Fetch summary\n        summary = wikipedia.summary(title, sentences=8, auto_suggest=False, redirect=True)\n    except BaseException as e:\n        return f\"Failed to execute. Error: {repr(e)}\"\n    return f\"Successfully executed:\\nWikipedia summary: {summary}\"\n\n@tool\ndef stock_data_tool(\n    company_ticker: Annotated[str, \"The ticker symbol of the company to retrieve their stock performance data.\"], \n    num_days: Annotated[int, \"The number of business days of stock data required to respond to the user query.\"]\n) -> str:\n    \"\"\"\n    Use this to look-up stock performance data for companies to retrieve a table from a CSV. You may need to convert company names into ticker symbols to call this function, e.g, Apple Inc. -> AAPL, and you may need to convert weeks, months, and years, into days.\n    \"\"\"\n    \n    # Load the CSV for the company requested\n    file_path = f\"data/{company_ticker}.csv\"\n\n    if os.path.exists(file_path) is False:\n        return f\"Sorry, but data for company {company_ticker} is not available. Please try Apple, Amazon, Meta, Microsoft, Netflix, or Tesla.\"\n    \n    stock_df = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n\n    # Ensure the index is in date format\n    stock_df.index = stock_df.index.date\n    \n    # Maximum num_days supported by the dataset\n    max_num_days = (stock_df.index.max() - stock_df.index.min()).days\n    \n    if num_days > max_num_days:\n        return \"Sorry, but this time period exceeds the data available. Please reduce it to continue.\"\n    \n    # Get the most recent date in the DataFrame\n    final_date = stock_df.index.max()\n\n    # Filter the DataFrame to get the last num_days of stock data\n    filtered_df = stock_df[stock_df.index > (final_date - pd.Timedelta(days=num_days))]\n\n    return f\"Successfully executed the stock performance data retrieval tool to retrieve the last *{num_days} days* of data for company **{company_ticker}**:\\n\\n{filtered_df.to_markdown()}\"\n\nfrom langchain_experimental.utilities import PythonREPL\n\nrepl = PythonREPL()\n\n@tool\ndef python_repl_tool(\n    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n):\n    \"\"\"Use this to execute python code. If you want to see the output of a value,\n    you should print it out with `print(...)`. This is visible to the user. The chart should be displayed using `plt.show()`.\"\"\"\n    try:\n        result = repl.run(code)\n    except BaseException as e:\n        return f\"Failed to execute. Error: {repr(e)}\"\n    return f\"Successfully executed the Python REPL tool.\\n\\nPython code executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\n\\nCode output:\\n\\`\\`\\`\\n{result}\\`\\`\\`\"","metadata":{"executionCancelledAt":null,"executionTime":1562,"lastExecutedAt":1748622611139,"lastExecutedByKernel":"efe21570-8ade-4aab-97ce-0b21ab6784fd","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from typing import Annotated\nimport wikipedia\nfrom langchain_core.tools import tool\nimport pandas as pd\nimport os\n\n@tool\ndef wikipedia_tool(\n    query: Annotated[str, \"The Wikipedia search to execute to find key summary information.\"],\n):\n    \"\"\"Use this to search Wikipedia for factual information.\"\"\"\n    try:\n        # Step 1: Search using query\n        results = wikipedia.search(query)\n        \n        if not results:\n            return \"No results found on Wikipedia.\"\n        \n        # Step 2: Retrieve page title\n        title = results[0]\n\n        # Step 3: Fetch summary\n        summary = wikipedia.summary(title, sentences=8, auto_suggest=False, redirect=True)\n    except BaseException as e:\n        return f\"Failed to execute. Error: {repr(e)}\"\n    result_str = f\"Successfully executed:\\nWikipedia summary: {summary}\"\n    return (\n        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n    )\n\n@tool\ndef stock_data_tool(\n    company_ticker: Annotated[str, \"The ticker symbol of the company to retrieve their stock performance data.\"], \n    num_days: Annotated[int, \"The number of business days of stock data required to respond to the user query.\"]\n) -> str:\n    \"\"\"\n    Use this to look-up stock performance data for companies to retrieve a table from a CSV. You may need to convert company names into ticker symbols to call this function, e.g, Apple Inc. -> AAPL, and you may need to convert weeks, months, and years, into days.\n    \"\"\"\n    \n    # Load the CSV for the company requested\n    file_path = f\"data/{company_ticker}.csv\"\n\n    if os.path.exists(file_path) is False:\n        return f\"Sorry, but data for company {company_ticker} is not available. Please try Apple, Amazon, Meta, Microsoft, Netflix, or Tesla.\"\n    \n    stock_df = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n\n    # Ensure the index is in date format\n    stock_df.index = stock_df.index.date\n    \n    if num_days > stock_df.shape[0]:\n        return \"Sorry, but this time period exceeds the data available. Please reduce it to continue.\"\n    \n    # Get the most recent date in the DataFrame\n    final_date = stock_df.index.max()\n\n    # Filter the DataFrame to get the last num_days of stock data\n    filtered_df = stock_df[stock_df.index >= (final_date - pd.Timedelta(days=num_days+2))]\n\n    return f\"Successfully executed the stock performance data retrieval tool to retrieve the last *{num_days} days* of data for company **{company_ticker}**:\\n\\n{filtered_df.to_markdown()}\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n\nfrom langchain_experimental.utilities import PythonREPL\n\nrepl = PythonREPL()\n\ncode = f\"\"\"\nimport numpy as np\n\narr = np.arange(0, 9)\nprint(arr)\nprint(2 * arr)\n\"\"\"\n\n@tool\ndef python_repl_tool(\n    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n):\n    \"\"\"Use this to execute python code. If you want to see the output of a value,\n    you should print it out with `print(...)`. This is visible to the user. The chart should be displayed using `plt.show()`.\"\"\"\n    try:\n        result = repl.run(code)\n    except BaseException as e:\n        return f\"Failed to execute. Error: {repr(e)}\"\n    result_str = f\"Successfully executed the Python REPL tool.\\n\\nPython code executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\n\\nCode output:\\n\\`\\`\\`\\n{result}\\`\\`\\`\"\n    return (\n        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n    )"},"cell_type":"code","id":"9a13184f-f26c-458d-af96-c0db734e88f4","outputs":[],"execution_count":2},{"source":"### ‚ùìIntroducing conditional edges\n\nOne of the problems with our current agentic system is that the chatbot node was always directed into the tools node, regardless of whether the user input requires the tools or not. This means that the LLM isn't really making a decision, as there is no other choice but to proceed.\n\nLangGraph provides ***conditional edges***, which are like splits in the workflow where the agent can choose which way to go.","metadata":{},"cell_type":"markdown","id":"57c0fc5a-7689-49fc-999e-0b5db5f041e8"},{"source":"**Re-bind the tools to the LLM and re-define the `llm_node()` function.**","metadata":{},"cell_type":"markdown","id":"288ba76c-68a6-46ab-b397-320240b531c2"},{"source":"from typing import Annotated\nfrom typing_extensions import TypedDict\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import add_messages\nfrom langchain_openai import ChatOpenAI\n\nclass State(TypedDict):\n    messages: Annotated[list, add_messages]\n\ngraph_builder = StateGraph(State)\n\n# Add three tools to the list: wikipedia_tool, stock_data_tool, and python_repl_tool\ntools = [wikipedia_tool, stock_data_tool, python_repl_tool]\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\n\n# Tell the LLM which tools it can call\nllm_with_tools = ____\n\ndef llm_node(state: State):\n    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}","metadata":{"executionCancelledAt":null,"executionTime":799,"lastExecutedAt":1748622752546,"lastExecutedByKernel":"efe21570-8ade-4aab-97ce-0b21ab6784fd","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from typing import Annotated\nfrom typing_extensions import TypedDict\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import add_messages\nfrom langchain_openai import ChatOpenAI\n\nclass State(TypedDict):\n    messages: Annotated[list, add_messages]\n\ngraph_builder = StateGraph(State)\n\n# Add three tools to the list: wikipedia_tool, stock_data_tool, and python_repl_tool\ntools = [wikipedia_tool, stock_data_tool, python_repl_tool]\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.environ[\"JAMES_OPENAI_KEY\"])\n\n# Tell the LLM which tools it can call\nllm_with_tools = llm.bind_tools(tools)\n\ndef chatbot(state: State):\n    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"},"id":"0f8f8764-dc83-42ed-bec2-f7307162db3f","cell_type":"code","execution_count":3,"outputs":[]},{"source":"### ‚ûï Adding the conditional edge\n\nNow to build the graph! We need to build `\"llm\"` and `\"tools\"` nodes as before, but this time, you need to add a conditional edge to the `\"llm\"` node, so it can use the `tools_condition` function to decide whether to trigger the tools or end. `\"tools\"` must also be connected back to `\"llm\"` so the LLM can decide whether it is able to end the task or trigger another tool.\n\nThe `.add_conditional_edges()` method is similar to `.add_edge()`, taking a source node to start at, but then it takes a function to evaluate how to proceed, and a dictionary indicating which nodes to continue to, depending on the evaluation.\n\nThe following code uses the built-in `tools_condition`, which asks the model to decide if a tool is required; if so, it moves to the `\"tools\"` node, if not, it moves to the `END` node (which is named `__end__`).\n\n```py\ngraph_builder.add_conditional_edges(START, tools_condition, {\"tools\", END})\n```","metadata":{},"id":"6b338ff4-a8d7-4b4f-81af-333fe9e1bfc6","cell_type":"markdown"},{"source":"**Complete the code to define the graph containing conditional edges from the LLM node to the tool node.**","metadata":{},"cell_type":"markdown","id":"77a2e71d-f6cd-4c4f-b2b2-3dfcc32cdbbf"},{"source":"from langgraph.prebuilt import ToolNode, tools_condition\n\n# Create the llm and tools nodes\ngraph_builder.add_node(____)\ntool_node = ToolNode(tools=tools)\ngraph_builder.add_node(____)\n\n# Add the edges\ngraph_builder.add_edge(____)\ngraph_builder.____\ngraph_builder.add_edge(____)\n\ngraph = graph_builder.compile()","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1748622780936,"lastExecutedByKernel":"efe21570-8ade-4aab-97ce-0b21ab6784fd","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from langgraph.prebuilt import ToolNode, tools_condition\n\n# Create the chatbot and tools nodes\ngraph_builder.add_node(\"chatbot\", chatbot)\ntool_node = ToolNode(tools=tools)\ngraph_builder.add_node(\"tools\", tool_node)\n\n# Add the edges\ngraph_builder.add_edge(START, \"chatbot\")\ngraph_builder.add_conditional_edges(\"chatbot\", tools_condition, [\"tools\", END])\ngraph_builder.add_edge(\"tools\", \"chatbot\")\n\ngraph = graph_builder.compile()"},"id":"4fcafade-6c28-4099-afdc-02e25fbd5b2e","cell_type":"code","execution_count":4,"outputs":[]},{"source":"Run the code to visualize the updated graph!","metadata":{},"id":"b4464fda-9578-484b-bf0a-aeedb9b3a978","cell_type":"markdown"},{"source":"# Visualize your graph\ngraph","metadata":{"executionCancelledAt":null,"executionTime":78,"lastExecutedAt":1748622796127,"lastExecutedByKernel":"efe21570-8ade-4aab-97ce-0b21ab6784fd","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from IPython.display import Image, display\n\ntry:\n    display(Image(graph.get_graph().draw_mermaid_png()))\nexcept Exception:\n    # This requires some extra dependencies and is optional\n    pass"},"id":"beecaaa1-e082-420d-8e3d-6fd94018eb62","cell_type":"code","execution_count":5,"outputs":[]},{"source":"Nicely done! The input is enters the chatbot node, which then decides whether a tool needs to be triggered. If it is required, the tools are called; if not, the chatbot responds using its knowledge and ends the interaction.\n\nTry re-running the same inputs as before to spot the difference!\n\n1. Tell me about Apple Inc.\n2. AAPL stock price.\n3. My name is `<Insert your name>`.\n4. Plot an Open price time-series of AAPL.","metadata":{},"id":"e2f7b37a-d6bf-44c5-a093-24ab4d6aab8f","cell_type":"markdown"},{"source":"from course_helper_functions import pretty_print_messages\n\nfor chunk in graph.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me about Apple Inc.\"}]}\n):\n    pretty_print_messages(chunk)","metadata":{"executionCancelledAt":null,"executionTime":1125,"lastExecutedAt":1748622840348,"lastExecutedByKernel":"efe21570-8ade-4aab-97ce-0b21ab6784fd","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def stream_graph_updates(graph_obj, user_input: str):\n    # Streams user inputs to the graph, and extracts the response latest response\n    for event in graph_obj.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n        for value in event.values():\n            print(\"Assistant:\", value[\"messages\"][-1].content)\n\nwhile True:\n    try:\n        user_input = input(\"User: \")\n        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n            print(\"Goodbye!\")\n            break\n\n        stream_graph_updates(graph, user_input)\n    except:\n        # Fallback if input() is not available\n        user_input = \"What is an AI agent?\"\n        print(\"User: \" + user_input)\n        stream_graph_updates(graph, user_input)\n        break","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"id":"7734c301-5492-43e4-9d2f-c6aaf9b6cf1e","cell_type":"code","execution_count":7,"outputs":[]},{"source":"### üí° What did we learn here?\n\nOk, so there are a few things going on here:\n\n- The chatbot now responds to non-tool-related inputs, like telling it our name, rather than breaking.\n- There are at least two assistant responses for each input, the tool output, and the chatbot's output before it ends. This means the model can intepret the tool outputs and provide something more user-friendly than parsing the raw tool outputs.\n- Generating plots is still a little dodgy. This is because we have one agent managing all of our tools. Creating agents that specialize in specific tasks in the natural next step, so let's try this out!","metadata":{},"id":"f99dea6d-e837-42a1-8873-3b07405281ff","cell_type":"markdown"}],"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}